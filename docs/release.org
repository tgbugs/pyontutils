# -*- org-adapt-indentation: nil; org-edit-src-content-indentation: 0; -*-
#+TITLE: Python release workflow
#+OPTIONS: num:nil

* Using this file :noexport:
You can either [[https://orgmode.org/manual/Extracting-Source-Code.html][tangle]]
this file in emacs using =C-c C-v t= or you can tangle
the whole file from the command line using with the following.
#+begin_src bash :var THIS_FILE=(buffer-file-name) :results none
: ${THIS_FILE:="./release.org"}
emacs --batch \
      --load org \
      --load ob-shell \
      --eval "(org-babel-tangle-file \"${THIS_FILE}\")"
#+end_src

The core functionality is tangled to [[file:./../bin/python-release-functions.sh]].
It can be sourced in a shell or from a script using =source path/to/bin/python-release-functions.sh=
to make the functions defined in this file available for use.
* Python release process
Release workflow.

Don't tag a release on GitHub until all the tests pass,
the package contents are what we want and expect, and
you have run =push-release= to pypi testing and checked it.
Once they do, tag it with the version that you set below
so that everything is on the same page. If there are multiple
packages per repo the tag is usually prefixed with the module name.

Note that if you use the =--local ~/path/to/my/working/repo= option as the source repo
then =git pull= is called with =--force= since the assumption is that =git commit --amend=
may be used in certain cases.

*NEVER USE THESE FUNCTIONS ON YOUR WORKING REPO, YOU WILL LOOSE ANY STASHED WORK OR UNTRACKED FILES*

*WHEN YOU PUSH TO TEST*
Inspect _everything_ at https://test.pypi.org/project/${packagename}.
MAKE SURE THE HASHES MATCH (tail hashes vs curl output)
You can also check https://test.pypi.org/project/ontquery/#files
** Example release
#+NAME: release-examples
#+CAPTION: examples, this is horrible and dangerous, never do this this way run the 3 commands separately
#+BEGIN_SRC bash :eval never :noweb yes
source ~/git/pyontutils/bin/python-release-functions.sh
SOMEVAR=some-value \
build-release org repo folder packagename version --some-arg
PYTHONPATH=~/git/pyontutils: SCICRUNCH_API_KEY=$(cat ~/ni/dev/secrets.yaml | grep tgbugs-travis | awk '{ print $2 }') \
build-release tgbugs ontquery ontquery ontquery 0.1.0 --release
exit  # if try to copy paste this block terminate here to prevent dumbs
push-release ontquery ~/nas/software-releases ontquery 0.1.0
# DO GitHub RELEASE HERE
are-you-sure && \
final-release ~/nas/software-releases ontquery 0.1.0
#+END_SRC


This is a reasonable time to tag the release on GitHub.
* Config files
#+CAPTION: [[file:${HOME}/.pypirc]] on the release host (only need to create once)
#+BEGIN_SRC toml
[distutils]
index-servers =
    pypi
    test

[pypi]
repository: https://upload.pypi.org/legacy/
username: your-username

[test]
repository: https://test.pypi.org/legacy/
username: your-username
password: set-this-one-for-simplicity
#+END_SRC
* Code
** Python release functions
Tangle this block so you can source [[file:./../bin/python-release-functions.sh]]
#+NAME: all-blocks
#+CAPTION: run this to export all the things
#+HEADER: :tangle ../bin/python-release-functions.sh :comments noweb
#+BEGIN_SRC bash :eval never :noweb yes
<<&build-release>>
<<&push-release>>
# TODO github-release
<<&final-release>>
#+END_SRC
** Build release
#+name: &default-python-version
: 3.9

#+NAME: &vars-build-release
#+begin_src bash :eval never :exports code :noweb yes
local POSITIONAL=()
local INTEGRATION_PACKAGES=()
while [[ $# -gt 0 ]]
do
key="$1"
case $key in
    -l|--local)           local CLONEFROM="$2"; shift; shift ;;
    -f|--artifact-folder) local ARTIFACT_FOLDER="$2"; shift; shift ;;
    -p|--base-path)       local BASE_PATH="$2"; shift; shift ;;
    -b|--branch)          local BRANCH="$2"; shift; shift ;;
    -i|--install-package) local INTEGRATION_PACKAGES+=("$2"); shift; shift ;;
    --python)             local PYTHON_VERSION="$2"; shift; shift ;;
    --tag-no-rename)      local TAG_NO_RENAME=YES; shift ;;
    --tag-prefix)         local TAG_PREFIX=YES; shift ;;
    --keep-artifacts)     local KEEP_ARTIFACTS=YES; shift ;;
    --no-test)            local NO_TEST=YES; shift;;
    --debug)              local DEBUG=YES; shift ;;
    ,*)                    local POSITIONAL+=("$1"); shift ;;
esac
done

local PYTHON_VERSION=${PYTHON_VERSION:-<<&default-python-version()>>}
local org=${POSITIONAL[0]}
local repo=${POSITIONAL[1]}
local folder=${POSITIONAL[2]}
local packagename=${POSITIONAL[3]}
local version=${POSITIONAL[4]}
local REST=${POSITIONAL[@]:5}  # remaining position passed along
echo $REST

if [[ ${folder} == *"/"* || -n ${TAG_PREFIX} ]]; then
    local tag=${packagename}-${version}
    local clone_target=${repo}-${packagename}-${PYTHON_VERSION}  # prevent git lock collisions
    folder="${clone_target}/${folder#*/}"
else
    local tag=${version}
    local clone_target=${repo}-${PYTHON_VERSION}
    folder=${clone_target}
fi

# TODO make sure no vars are null

: ${BASE_PATH:=/tmp/python-releases}  # allow override for cases where /tmp causes test failure

[ -d "${BASE_PATH}" ] || mkdir -p "${BASE_PATH}"

echo $org $repo $clone_target $folder $packagename $version $tag $CLONEFROM $ARTIFACT_FOLDER $BASE_PATH ${INTEGRATION_PACKAGES[@]}
#+end_src

#+NAME: &build-release
#+begin_src bash :eval never :exports code :noweb yes
build-release () {
    # example
    # build-release org    repo     folder   packagename version
    # build-release tgbugs ontquery ontquery ontquery    0.0.8

    <<&vars-build-release>>

    cd ${BASE_PATH}  # ensure we are always working in tmp for the rest of the time

    TEST_PATH="${BASE_PATH}/release-testing/${PYTHON_VERSION}-${packagename}"  # allow multiple builds at the same time

    if [ -d ${repo} ]; then
        rm -rf "${TEST_PATH}"
    fi
    mkdir -p "${TEST_PATH}"

    if [ -d ${clone_target} ]; then
        pushd ${clone_target}
        rurl="$(git remote get-url origin)"
        if [[ -z ${CLONEFROM} && ! $rurl =~ "https://" && ! $rurl =~ "git@" ]]; then
            git remote set-url origin https://github.com/${org}/${repo}.git ${clone_target}
        elif [[ -n ${CLONEFROM} && "$rurl" != "${CLONEFROM}" ]]; then
            git remote set-url origin "${CLONEFROM}"
        fi
        git fetch || return $?  # fail on bad clone to prevent testing against stale code
        git reset --hard origin/master
        git clean -dfx
        popd
    else
        if [[ -n ${CLONEFROM} ]]; then
            git clone ${CLONEFROM} ${clone_target}
        else
            git clone https://github.com/${org}/${repo}.git ${clone_target}
        fi
    fi
    # TODO __version__ check against ${version}

    pushd "${folder}" || return $?  # or subfolder

    if [[ $(git tag -l ${tag}) ]]; then
        gsh=$(git rev-parse --short HEAD)
        verspath=$(grep -l '__version__.\+=' $(ls */*.py))
        # this commit count doesn't quite match the one we get
        # from the python code which checks only files in sdist
        commit_count=$(git rev-list ${tag}..HEAD -- . | wc -l)
        version=${version}+${commit_count}.${gsh}
        tag=${tag}+${gsh}
        echo "${tag} has already been released for this repo!"
        echo "running with ${tag} ${version} instead"
        # FIXME need to make sure that we prevent releases in this case
    fi

    if [[ -n ${BRANCH} ]]; then
        git checkout ${BRANCH}
        git pull  # in the event that a local branch already exists
    else
        git checkout -f master  # just like clean -dfx this should wipe changes just in case
    fi
    #git checkout ${version}  # only if all tests are go and release is tagged

    if [[ -n ${verspath} ]]; then  # apply local version after checkout
        sed -i '/__version__/d' "${verspath}"  # handle bad semantics for find_version
        echo "__version__ = '${version}'" >> "${verspath}"
    fi

    ## build release artifacts
    PYTHONPATH=${PYTHONPATH}$(realpath .) python setup.py sdist $REST  # pass $REST along eg for --release
    if [ $? -ne 0 ]; then
        echo "setup.py failed"
        popd > /dev/null
        return 1
    fi

    # build the wheel from the sdist NOT from the repo
    pushd dist/
    tar xvzf ${packagename}-${version}.tar.gz
    pushd ./${packagename}-${version}/
    python setup.py bdist_wheel $@  # this should NOT be $REST, because we don't call it with --release (among other things)
    mv dist/*.whl ../
    popd  # from ./${packagename}-${version}/
    rm -r ./${packagename}-${version}/
    popd  # from dist/

    ## testing
    if [[ -z ${NO_TEST} ]]; then
        unset PYTHONPATH
        cp dist/${packagename//-/*}-${version}* "${TEST_PATH}"

        pushd "${TEST_PATH}"
        tar xvzf ${packagename}-${version}.tar.gz
        if [ $? -ne 0 ]; then
            echo "tar failed, probably due to a version mismatch"
            popd > /dev/null
            popd > /dev/null
            return 1
        fi
        pushd ${packagename}-${version}

        # pipenv --rm swears no venv exists, if no Pipfile
        # exists even if adding a Pipfile will magically
        # reveal that there was in fact a venv and thus that
        # every other pipenv command knows about it but
        # naieve little rm is kept in the dark, so we yell
        # into the 'void' just to make sure
        touch Pipfile
        # FIXME need a way to do concurrent builds on different python versions
        # running pipenv --rm breaks that
        pipenv --rm  # clean any existing env
        pipenv --python $PYTHON_VERSION  # for some reason 3.6 lingers in some envs
        if [[ -n ${DEBUG} ]]; then
            pipenv run pip install pudb ipdb  # install both for simplicity
            NOCAP='-s'
        fi

        # local package server
        local maybe_eiu=()
        if [[ -n ${ARTIFACT_FOLDER} ]]; then
            #pipenv run pip install requests-file || return $?  # sadly this does not work
            #--extra-index-url "file://$(realpath ${ARTIFACT_FOLDER})" \

            # run a local pip package server for integration testing

            # it would be great to be able to pass 0 for the port to http.server
            # but http.server doesn't flush stdout correctly until process exit
            # so we use socket to get a random port and the use that and hope
            # that some other process doesn't randomly grab it in between
            # spoilers: some day it will
            PORT=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')
            python -m http.server \
                $PORT \
                --bind 127.0.0.1 \
                --directory "${ARTIFACT_FOLDER}" \
                > /dev/null 2>&1 &  # if you need to debug redirect somewhere other than /dev/null
            local TOKILL=$!
            maybe_eiu+=(--extra-index-url "http://localhost:${PORT}")
        fi

        if [[ -n ${INTEGRATION_PACKAGES} ]]; then
            echo $(color yellow)installing integration packages$(color off) ${INTEGRATION_PACKAGES[@]}
            pipenv run pip install \
                "${maybe_eiu[@]}" \
                ${INTEGRATION_PACKAGES[@]} || return $?
        fi

        echo $(color yellow)installing$(color off) ${packagename}
        pipenv run pip install \
            "${maybe_eiu[@]}" \
                -e .[test] || local CODE=$?

        [[ -n $TOKILL ]] && kill $TOKILL
        [[ -n $CODE && $CODE -ne 0 ]] && return $CODE

        pipenv run pytest ${NOCAP} || local FAILURE=$?
        # FIXME popd on failure ... can't && because we loose the next popd instead of exiting
        # everything should pass if not, keep going until it does
        popd  # from ${packagename}-${version}
        popd  # from "${TEST_PATH}"
    else
        # treat unrun tests as if they failed
        echo "$(color yellow)TESTS WERE NOT RUN$(color off)";
        local FAILURE=1
    fi

    # background here to twine?
    popd  # from "${folder}"

    if [[ -n ${FAILURE} ]]; then
        echo "$(color red)TESTS FAILED$(color off)";
    fi

    # deposit the build artifacts
    if [[ -n ${ARTIFACT_FOLDER} ]]; then
        if [ ! -d "${ARTIFACT_FOLDER}/${packagename}" ]; then
            mkdir -p "${ARTIFACT_FOLDER}/${packagename}"
        fi
        cp "${folder}"/dist/${packagename//-/*}-${version}* "${ARTIFACT_FOLDER}/${packagename}"
        echo "build artifacts have been copied to ${ARTIFACT_FOLDER}/${packagename}"
    fi

    # FIXME need multiple repos when packages share a repo
    # basically a test for if [[ package == repo ]] or something
    if [[ -n ${KEEP_ARTIFACTS} ]]; then
        echo "$(color yellow)keeping artifacts$(color off)"
    elif [[ -n ${CLONEFROM} || ${BRANCH} ]]; then
        rm ${folder}/dist/${packagename//-/*}-${version}*
        if [[ -n ${CLONEFROM} ]]; then
            echo "$(color yellow)release build was cloned from a local source$(color off) ${CLONEFROM}"
        else
            echo "$(color yellow)release build was cloned from a specific branch$(color off) ${BRANCH}"
        fi
        echo "$(color ltyellow)removing the build artifacts from ${folder}/dist$(color off)"
        echo "$(color ltyellow)to prevent release from a private source$(color off)"
    fi
}
#+end_src

** Push release
#+NAME: &push-release
#+BEGIN_SRC bash :eval never :exports code :noweb yes
function push-release () {
    # example
    # push-release folder   software_releases_path    packagename version
    # push-release ontquery ~/nas/software-releases   ontquery    0.0.8
    local folder=$1
    shift
    local software_releases_path=$1
    shift
    local packagename=$1
    shift
    local version=$1
    shift

    local PYTHON_VERSION=${PYTHON_VERSION:-<<&default-python-version()>>}
    local repo=${folder%/*}  # XXX this more or less matches current conventions
    if [[ ${folder} == *"/"* ]]; then
        local clone_target=${repo}-${packagename}-${PYTHON_VERSION}  # prevent git lock collisions
        folder="${clone_target}/${folder#*/}"
    else
        local clone_target=${repo}-${PYTHON_VERSION}
        folder=${clone_target}
    fi

    # NOTE Always deploy from ${folder}/dist NOT from ARTIFACT_FOLDER
    # This prevents accidental release of testing builds
    rsync -a -v --ignore-existing ${folder}/dist/${packagename//-/*}-${version}{-,.tar}* ${software_releases_path}/ || return $?
    pushd ${software_releases_path}
    sha256sum ${packagename//-/*}-${version}{-,.tar}* >> hashes
    twine upload --repository test ${packagename//-/*}-${version}{-,.tar}* || return $?
    sleep 1
    echo "test pypi hashes"
    curl https://test.pypi.org/pypi/${packagename}/json | python -m json.tool | grep "\(sha256\|filename\)" | grep -B1 "${version}" | awk '{ gsub(/"/, "", $2); printf("%s ", $2) }' | sed 's/,\ /\n/g'
    echo "local hashes"
    grep "${packagename//-/.}-${version}" hashes
    echo go inspect https://test.pypi.org/project/${packagename}
    echo and go do the github release
    popd
}
#+END_SRC
** TODO GitHub release
#+NAME: github-release
#+BEGIN_SRC python :eval never
import requests
from sparcur.utils
#from sparcur.utils import mimetype  # FIXME or something like that
# TODO api token

suffix_to_mime = {
    '.whl': 'application/octet-stream',  # technically zip ...
    '.gz': 'application/gzip',
    '.zip': 'application/zip',
}


class BadAssetSuffixError(Exception):
    """ u wot m8 !? """


def upload_assets(upload_base, version, *asset_paths):
    for asset in asset_paths:
        name = asset.name
        requests.post()


def github_release(org, repo, version, hashes, *assets, branch='master'):
    """ hashes should be the output of sha256sum {packagename}-{version} """
    # FIXME pyontutils violates some assumptions about 1:1 ness here

    asset_paths = tuple(Path(a).resolve() for a in assets)
    bads = [p.suffix  for p in asset_paths if p.suffix not in suffix_to_mime]
    if bads:
        raise BadAssetSuffixError(' '.join(bads))

    base = 'https://api.github.com'
    path = f'/repos/{org}/{repo}/releases'
    headers = {'Accept': 'application/vnd.github.v3+json'}
    json_data = {'tag_name': version,
                 'target_commitish': branch,
                 'name': version,
                 'body': hashes,
                 'draft': False,  # ok because we can add assets later
                 'prerelease': False}

    url = base + path
    resp = requests.post(url, headers=headers, json=json_data)
    rel_J = resp.json()
    uu = rel_j['upload_url']

    upload_base = uu.replace('{?name,label}', '')

    upload_assets(upload_base, *asset_paths)
#+END_SRC

** Final release
#+NAME: &final-release
#+CAPTION: on the release host final upload from previous block
#+CAPTION: you will need to enter your password
#+BEGIN_SRC bash :eval never :exports code
function final-release () {
    # example
    # final-release software_releases_path    packagename version
    # final-release ~/nas/software-releases   ontquery    0.0.8
    local software_releases_path=$1
    shift
    local packagename=$1
    shift
    local version=$1
    shift

    pushd ${software_releases_path}

    twine upload --repository pypi ${packagename/-/*}-${version}{-,.tar}* || return $?  # enter password here

    sleep 1
    echo "pypi hashes"
    curl https://pypi.org/pypi/${packagename}/json | python -m json.tool | grep "\(sha256\|filename\)" | grep -B1 "${version}" | awk '{ gsub(/"/, "", $2); printf("%s ", $2) }' | sed 's/,\ /\n/g'
    echo "local hashes"
    grep "${packagename}-${version}" hashes
    echo go inspect https://pypi.org/project/${packagename}

    popd
}
#+END_SRC
** TODO Next version                                               :noexport:
#+NAME: release-next
#+HEADER: :shebang "#!/usr/bin/env python3"
#+begin_src python :tangle ./../bin/release-next :tangle-mode (identity #o755)
"""python package release workflows

Usage:
    release-next [options]
    release-next info [options] [<path>...]
    release-next bump [current dev pre a b rc release micro minor major post local] [options] [<path>...]

Options:
    -p --pretend            do a dry run to see what would be done
    -c --component=PHASE    which component to bump
    -t --test               run tests
    -d --debug              debug mode
    -h --help               show this
    -n --no-network         no network calls
"""
import setuptools
from setuptools.dist import Distribution
from setuptools.command.egg_info import manifest_maker, FileList, log as eilog
from packaging.version import parse as parse_version
import importlib.util
from urllib.parse import urlparse
import requests
import augpathlib as aug
from pyontutils import clifun as clif

eilog.set_threshold(99)

last_output = [None]
def fake_setup(*args, **kwargs):
    last_output[0] = args, kwargs


setuptools.setup = fake_setup


def vinc(thing, prefix=None):
    if isinstance(thing, tuple):
        return (*thing[:-1], vinc(thing[-1]))
    elif isinstance(thing, str):
        raise TypeError("don't know how to increment a string")
    else:
        if thing is None:
            if prefix is not None:
                return prefix, 0
            else:
                return 0
        else:
            return thing + 1

def current_state(ver):
    if ver.local is not None: return 'local'
    if ver.post is not None: return 'post'
    if ver.pre is not None: return ver.pre[0]
    if ver.dev is not None: return 'dev'
    return 'release'


def logic(cstate, next_phase, rel_comp='release'):
    # if I want to go to major dev ? need modifier
    # TODO True -> toggle relese dev
    if next_phase == 'current': return cstate
    elif next_phase == 'dev':
        if cstate == 'dev': return cstate
        elif cstate in ('release', 'post', 'local'): return rel_comp, next_phase
        else: raise ValueError('cannot go to dev from a prerelease')
    elif next_phase == 'pre':  # this will bump a -> b -> rc since current will not
        if cstate == 'dev': return 'a'
        elif cstate == 'a': return 'b'
        elif cstate == 'b': return 'rc'
        elif cstate == 'rc': return 'rc'
        elif cstate in ('release', 'post', 'local'):
            return rel_comp, 'a'
        else: raise ValueError(f'wat c: {cstate} n: {next_phase}')
    elif next_phase in ('a', 'b', 'rc'):
        if cstate == 'dev': return next_phase
        elif cstate in ('a', 'b', 'rc') and cstate > next_phase:
            raise ValueError(f'cannot go back or skip a release c: {cstate} > n: {next_phase}')
        else: return rel_comp, next_phase
    elif next_phase == 'release':
        if cstate in ('dev', 'a', 'b', 'rc'): return None  # truncate
        else: return next_phase
    elif next_phase in ('major', 'minor', 'micro'): return next_phase
    elif next_phase == 'post':
        if cstate == 'release': return next_phase
        else: raise ValueError(f'can only post from release not from {cstate}')
    elif next_phase == 'local': return next_phase
    else: raise ValueError(f'wat c: {cstate} n: {next_phase}')


def cons_next(d, ver, next):
    # mutates in place
    if next in ('a', 'b', 'rc'):
        vp = ver.pre
        vn = vinc(vp[-1] if isinstance(vp, tuple) else vp)
        d.update(dict(pre=(next, vn)))
    elif next in ('dev', 'post'):
        d[next] = next, vinc(getattr(ver, next))
    elif next in ('release', 'major', 'minor', 'micro'):
        # FIXME this incorrect?
        release = d['release']
        if next == 'release':
            release = (*release[:-1], vinc(release[-1]))
        # FIXME index error or extent shorter version to that?
        elif next == 'major':
            release = vinc(release[0]), *[0 for _ in release[1:]]
        elif next == 'minor':
            release = (*release[:1], vinc(release[1]), *[0 for _ in release[2:]])
        elif next == 'micro':
            release = (*release[:2], vinc(release[2]), *[0 for _ in release[3:]])
        else: raise ValueError('hmr?')

        d['release'] = tuple(release)
    elif next == 'local':
        d.update(ver._version._asdict())
        d['local'] = vinc(ver.local),
    elif next is None:
        pass  # truncate to release from dev and pre
    else:
        raise ValueError('wat')


def next_version(ver, next_phase='current', rel_comp='release'):
    cstate = current_state(ver)
    next = logic(cstate, next_phase, rel_comp)
    d = dict(epoch=ver.epoch,
             release=ver.release,
             dev=None,
             pre=None,
             post=None,
             local=None,)
    if isinstance(next, tuple):
        dowhatnow, next = next
        cons_next(d, ver, dowhatnow)
        cons_next(d, ver, next)
    else:
        cons_next(d, ver, next)

    _nver = ver._version._replace(**d)
    _newver = ver.__class__('0')
    _newver._version = _nver
    # have to stringify so _key updates so comparisons are valid
    # yay for leaking implementation details
    newver = ver.__class__(str(_newver))
    return newver


class SetupPath(aug.RepoPath):
    # TODO get latest release info from github and pypi

    @property
    def setupfu(self):
        # FIXME sometimes this can fail if there are nested setup.py files !??!
        # and the base path is relative !??! temp workaround is to resolve all
        # paths before use, but there is still a bug
        with self.folder:
            #print('cwd', aug.AugmentedPath.cwd(), '\nsf', self.setup_file)
            spec = importlib.util.spec_from_file_location('setup', self.setup_file)
            setup = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(setup)
            args, kwargs = last_output[0]
            return setup, args, kwargs

    @property
    def setup_kwargs(self):
        if not hasattr(self, '_setup_kwargs'):
            mod, args, kwargs = self.setupfu
            self._setup_kwargs = kwargs

        return self._setup_kwargs

    @property
    def pypi_json(self):
        if not hasattr(self, '_pypi_json'):
            self._pypi_request = requests.get(f'https://pypi.org/pypi/{self.arg_packagename}/json')
            if not self._pypi_request.ok:
                # new package with no existing releases
                return

            self._pypi_json = self._pypi_request.json()

        return self._pypi_json

    @property
    def github_json(self):
        if not hasattr(self, '_github_json'):
            self._github_request = requests.get(self.remote_uri_api('/releases'))
            if not self._github_request.ok:
                return  # e.g. hit rate limit when testing

            self._github_json = self._github_request.json()

        return self._github_json

    @property
    def version_latest_pypi(self):
        pj = self.pypi_json
        if pj:
            return parse_version(pj['info']['version'])
        #return Version(self.pypi_json['info']['version'])

    @property
    def version_latest_released(self):
        # git, pypi, tag??
        pj = self.pypi_json
        if pj:
            vers = sorted(parse_version(_) for _ in pj['releases'])
            #vers = sorted(Version(_) for _ in self.pypi_json['releases'])
            return vers[-1]

    @property
    def version_latest_github(self):
        lpn = len(self.arg_packagename) + 1 if self.tag_prefix else 0
        tlg = self.tag_latest_github
        if tlg:
            version = tlg[lpn:]
            return parse_version(version)

    @property
    def tag_latest_github(self):
        gj = self.github_json
        if gj:
            if self.tag_prefix:
                these = [r for r in gj if self.arg_packagename in r['tag_name']]
            else:
                these = [r for r in gj if r['tag_name'][0] in '0123456789']

            if these:
                latest = these[0]
                return latest['tag_name']

    def version_next(self, next_phase='current', rel_comp='release'):
        # FIXME
        vlp = self.version_latest_pypi
        vlr = self.version_latest_released
        assert vlp == vlr, f'wat {vlp} != {vlr}'
        if vlp is not None:
            return next_version(vlp, next_phase=next_phase, rel_comp=rel_comp)
        elif self.version_repo:
            return self.version_repo
        else:
            return parse_version('0.0.0.dev0')  # FIXME hardcoded default zeroth version

    @property
    def tag_prefix(self):
        # TODO tag_prefix_anyway
        tag_prefix = False  # if for some reason we want to regularize version tagging that can go in the repo
        return self.setup_file.parent != self.working_dir or tag_prefix

    @property
    def tag(self):
        # the logic is that if module folder name == package name or we override via tag no rename
        # then there is no prefix expected, otherwise the prefix is ALWAYS the package name

        # FIXME there is no good way to do this without having it specified somewhere in
        # the repo that some package has priority for prefixless versions
        # also if someone renames the outer folder, which is entirely allowed and possible
        # then the tag will change, however I think I can do better because the logic is
        # actually about whether setup.py is in the root of the repo NOT whether names
        # match ... HRM

        if self.tag_prefix:
            match_version = self.arg_packagename + '-*'
        else:
            match_version = '[0-9]*'

        try:
            return self.repo.git.describe('--abbrev=0', '--tags', f'--match={match_version}')
        except self._git.exc.GitCommandError as e:
            pass  # no tag for this version

    @property
    def version_tag(self):
        lpn = len(self.arg_packagename) + 1 if self.tag_prefix else 0
        if self.tag:
            version = self.tag[lpn:]
            return parse_version(version)

    @property
    def version_repo(self):
        return parse_version(self.setup_kwargs['version'])
        #return Version(self.setup_kwargs['version'])

    @property
    def _version_new(self):  # XXX unused
        # TODO cases dev normal
        # want dev release but repo is at an unreleased normal
        # want normal, already released this one
        # want dev, already released this one
        # want *, repo skips a version
        return self.version_repo
        raise NotImplementedError('TODO')

    @property
    def release_files(self):
        # use to get the list of files that will be included in a release
        # so that we can limit the log to only those files
        mm = manifest_maker(Distribution())
        mm.distribution.script_name = 'setup.py'  # FIXME check path on this one
        mm.manifest = 'MANIFEST.in'
        mm.filelist = FileList()
        with self.folder:
            mm.add_defaults()
            mm.read_template()
            mm.add_license_files()

        mm.prune_file_list()
        mm.filelist.files += ['MANIFEST.in']
        mm.filelist.sort()
        mm.filelist.remove_duplicates()
        return mm.filelist.files

    def commits_since_last_release(self):
        try:
            rfs = [(self.folder / f) for f in self.release_files]
        except FileNotFoundError as e:  # no MANIFEST.in usually
            print(e)
            rfs = [self.folder]

        _tag = self.tag
        tag = _tag if _tag else ''
        log = self.repo.git.log("--format='%aI %an %h %s'",
                                f'{tag}..HEAD',
                                '--', *rfs)
        entries = [e[1:-1] for e in log.split('\n')]
        return entries

    @property
    def module_init_file(self):
        return self.module / '__init__.py'

    @property
    def module(self):
        kwargs = self.setup_kwargs
        name = kwargs['name']
        packages = kwargs['packages']
        for package in packages:
            if package == name:
                return self.folder / name

        raise NotImplementedError(f'Don\'t know how to release packages whose name does not match a package name. {name} {packages}')

    @property
    def setup_file(self):
        return self.folder / 'setup.py'

    @property
    def folder(self):
        if not self.is_absolute() or '..' in self.parts:
            return self.resolve().folder

        if self.is_dir():
            for f in self.glob('setup.py'):
                return self

        if self.parent == self:
            raise ValueError('No setup.py found.')

        return self.parent.folder

    @property
    def arg_org(self):
        u = urlparse(self.remote_uri_human())
        _, org, repo, *_ = u.path.split('/')
        return org

    @property
    def arg_repo(self):
        u = urlparse(self.remote_uri_human())
        _, org, repo, *_ = u.path.split('/')
        return repo

    @property
    def arg_folder(self):
        return self.folder.relative_to(self.working_dir.parent)

    @property
    def arg_packagename(self):
        return self.setup_kwargs['name']

    @property
    def arg_rest(self):
        # TODO
        return ''

    def command(self, next_phase='current', rel_comp='release'):
        rest = self.arg_rest
        rest = ' ' + self.rest if rest else ''
        nv = self.version_next(next_phase, rel_comp)
        return (
            f'build-release {self.arg_org} {self.arg_repo} {self.arg_folder} '
            f'{self.arg_packagename} {nv}{rest}')

    def bump(self, next_phase='current', rel_comp='release', pretend=False):
        nv = self.version_next(next_phase=next_phase, rel_comp=rel_comp)
        if nv == self.version_latest_released:  # we should never hit this branch
            raise ValueError(f'already released {nv}')
        elif nv == self.version_repo:
            raise ValueError(f'already bumped to {nv} but not released (though maybe not committed?)')
        breakpoint()
        if pretend:
            print('would bump module', self.module_init_file,
                  'for package name', self.setup_kwargs['name'],
                  'from', self.version_repo,
                  'to', nv)
            return
        # make the change in __init__ (or wherever)
        # commit the change
        # do NOT PUSH the change

SetupPath._bind_flavours()


def main():
    import sys
    from pprint import pprint
    options, *ad = Options.setup(__doc__, version='release 0.0.0')
    main = Main(options)
    if main.options.debug:
        print(main.options)

    if main.options.no_network:
        SetupPath._github_json = None
        SetupPath._pypi_json = None

    out = main()

    def wnv(v, n):
        try:
            return next_version(v, n)
        except Exception as e:
            return 'ERROR', v, n, e

    # TODO need an auto version bump and commit command
    if options.test:
        spn = SetupPath('~/git/rdflib').expanduser()
        asdf = sorted([parse_version(_) for _ in spn.pypi_json['releases'].keys()])
        pprint(asdf)
        pprint([wnv(v, 'current') for v in asdf])
        pprint([wnv(v, 'dev') for v in asdf])  # FIXME dev and pre implicitly bump to release but some may need to spec
        pprint([wnv(v, 'pre') for v in asdf])
        pprint([wnv(v, 'a') for v in asdf])
        pprint([wnv(v, 'b') for v in asdf])
        pprint([wnv(v, 'rc') for v in asdf])
        pprint([wnv(v, 'release') for v in asdf])
        pprint([wnv(v, 'micro') for v in asdf])
        pprint([wnv(v, 'minor') for v in asdf])
        pprint([wnv(v, 'major') for v in asdf])
        pprint([wnv(v, 'post') for v in asdf])
        pprint([wnv(v, 'local') for v in asdf])

    #breakpoint()
    return out


class Options(clif.Options):

    _phases = ('current', 'dev', 'pre', 'a', 'b', 'rc',
               'release', 'micro', 'minor', 'major', 'post', 'local')

    @property
    def paths(self):
        if self._args['<path>']:
            # FIXME without the .resolve() weird bugs appear
            return [SetupPath(p).resolve() for p in self._args['<path>']]
        else:
            return [SetupPath.cwd()]

    @property
    def next_phase(self):
        for phase in self._phases:
            if phase in self._args and self._args[phase]:
                return phase

        return 'current'

    @property
    def rel_comp(self):
        if self.component:
            if self.component not in self._phases:
                raise ValueError(f'Bad phase {self.component}')

            return self.component
        else:
            return 'release'


class Main(clif.Dispatcher):
    def info(self):
        for sp in self.options.paths:
            cslr = sp.commits_since_last_release()
            print('path                 ', sp)
            print('package              ', sp.setup_kwargs['name'])
            print('commits since release', len(cslr))
            print('next                 ', sp.version_next(self.options.next_phase, self.options.rel_comp))
            print('repo module version  ', sp.version_repo)
            print('latest release pypi  ', sp.version_latest_pypi)
            print('latest release github', sp.version_latest_github)
            print('latest repo tag      ', sp.version_tag)  # should not update until after github release?
            print(sp.command(self.options.next_phase, self.options.rel_comp))
            print('\n'.join(cslr))
            print()

    def bump(self):
        for sp in self.options.paths:
            sp.bump(
                next_phase=self.options.next_phase,
                rel_comp=self.options.rel_comp,
                pretend=self.options.pretend,
            )


if __name__ == '__main__':
    main()
#+end_src

#+NAME: release-next-old
#+BEGIN_SRC bash :eval never :exports neither
release-next () {
    # example
    # release-next path/to/folder/module/__init__.py
    # vs
    # release-next path/to/folder/module
    # vs
    # release-next path/to/folder

    # behavior should probably be to search recursively up until we find a setup.py file ...
    WORKING_DIR=$(git rev-parse --show-toplevel)
    MODULE_PATH=$(dirname INIT_PATH)
    FOLDER=$(dirname MODULE_PATH)
    SETUP_PATH="${FOLDER}/setup.py"
    ORG=
    # get folder package name
    # get version
    # find setup.py
}
#+END_SRC

** Utils
#+name: &are-you-sure
#+caption: also defined in [[file:../nifstd/scigraph/README.org::&are-you-sure][&are-you-sure]]
#+begin_src bash :eval never
function are-you-sure () {
    read -p "Are you sure you want to push the final release? yes/N " -n 1 choice
    # ((((
    case "${choice}" in
        yes|YES) echo ;;
        n|N) echo; echo "Not pushing final release."; return 1;;
        '?') echo; echo "$(set -o posix; set | grep -v '^_')"; return 1;;
        ,*)   echo; echo "Not pushing final release."; return 1;;
    esac
    echo "Pushing final release ..."
}
#+end_src
* Examples
These are examples. They may be out of date and already finished.
#+CAPTION: pyontutils examples
#+BEGIN_SRC bash :eval never
build-release tgbugs pyontutils pyontutils/librdflib librdflib 0.0.1
push-release pyontutils/librdflib ~/nas/software-releases librdflib 0.0.1
final-release ~/nas/software-releases librdflib 0.0.1

build-release tgbugs pyontutils pyontutils/htmlfn htmlfn 0.0.1
push-release pyontutils/htmlfn ~/nas/software-releases htmlfn 0.0.1
final-release ~/nas/software-releases htmlfn 0.0.1

build-release tgbugs pyontutils pyontutils/ttlser ttlser 1.0.0
push-release pyontutils/ttlser ~/nas/software-releases ttlser 1.0.0
final-release ~/nas/software-releases ttlser 1.0.0

build-release tgbugs pyontutils pyontutils pyontutils 0.1.2
push-release pyontutils ~/nas/software-releases pyontutils 0.1.2
final-release ~/nas/software-releases pyontutils 0.1.2

NIFSTD_CHECKOUT_OK=1 build-release tgbugs pyontutils pyontutils/neurondm neurondm 0.1.0
push-release pyontutils/neurondm ~/nas/software-releases neurondm 0.1.0
final-release ~/nas/software-releases neurondm 0.1.0

build-release tgbugs pyontutils pyontutils/nifstd nifstd-tools 0.0.1
#+END_SRC

* pyontutils full repo release testing
NOTE if you reuse a repo run =git clean -dfx= to clear all untracked files.
#+BEGIN_SRC bash :eval never
pushd /tmp
git clone https://github.com/tgbugs/pyontutils.git
pushd pyontutils
python setup.py sdist; cp dist/pyontutils* /tmp/release-testing
for f in {librdflib,htmlfn,ttlser,neurondm,nifstd}; do pushd $f; python setup.py sdist; cp dist/$f* /tmp/release-testing/; popd; done
pushd /tmp/release-testing
find -name "*.tar.gz" -exec tar xvzf {} \;
for f in {librdflib,htmlfn,ttlser,pyontutils,neurondm,nifstd}; do pushd $f*/; pip install -e .[test]; python setup.py test; popd; done
#+END_SRC

From inside /tmp/${repo}
#+NAME: bdist_wheel-from-sdist
#+CAPTION: build wheels from sdist never from repo directly
#+BEGIN_SRC bash :eval never
pushd dist/
tar xvzf pyontutils*.tar.gz
pushd pyontutils*/
python setup.py bdist_wheel
mv dist/*.whl ../
popd
rm -r ./pyontutils*/
popd

for f in {librdflib,htmlfn,ttlser,neurondm,nifstd}; do
pushd $f/dist
tar xvzf $f*.tar.gz
pushd $f*/
python setup.py bdist_wheel
mv dist/*.whl ../
popd
rm -r ./$f*/
popd
done
#+END_SRC
